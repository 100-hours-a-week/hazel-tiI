## 날짜: 2024-12-20

## 강의 내용 복습 

### github actions
- 깃허브에서 제공하는 CI/CD 도구로 코드 변경 시 테스트 자동 실행, 빌드 및 배포 자동화가 가능하다. 
- 가상화된 서버에서 실행되며 다양한 자동화 작업을 지원한다. 
#### workflow 
- github actions의 작업 흐름을 정의하는 파일이다. 
- `.github/workflows/` 디렉토리에 `.yml` 파일 형식으로 저장된다.  
#### event
- workflow 실행 트리거로 특정 조건이나 이벤트 발생 시 작업을 시작한다.  
- 자주 사용하는 트리거 
  - `push` : 코드를 `push` 할 때 실행 
  - `pull_request` : `pull request` 생성 시 실행
  - `workflow_dispatch` : 수동으로 실행    
#### job
- 병렬 또는 순차적으로 실행 가능한 작업 단위이다. 
#### step 
- `job` 안에서 실행되는 세부 작업이다. 
#### action
- 이미 존재하는 gihub actions를 가져와 재사용할 수 있는 작업 단위이다.
#### github actions의 특징
- 자동화 : 코드 변경 시 자동으로 테스트, 빌드, 배포가 실행된다.   
- 유연성 : 다양한 `workflow`와 `action`을 통해 복잡한 시나리오를 구현할 수 있다. 
- 커뮤니티 지원 : `gitHub Marketplace`를 통해 다양한 `action`을 찾아 재사용 할 수 있다. 

<br>


### github actions SSH 배포 실습 전 사전 준비 
1. AWS EC2 인스턴스를 실행한다. 
2. GitHub Access Token을 생성 및 등록한다.
- `GHCR`에 이미지를 `push` 하기 위해 `write:packages`, `read:packages` 권한을 가진 토큰을 생성한다.
  - 경로 : `깃허브 Settings>Developer Settings>Personal access tokens>Tokens` 
- 생성한 토큰을 GitHub Secrets에 등록한다. 
  - 경로 : `깃허브 리포지토리>Settings>Security>Secrets and variables>Actions` 
3. SSH키를 GitHub Secret을 등록한다. 
- AWS EC2에 접근하기 위해 SSH 키를 GitHub Secrets에 base64 인코딩을 한 뒤 등록한다. 
4. EC2 IP 및 사용자 명을 GitHub Secret에 등록한다. 

#### github action workflow 파일의 환경 변수
- GitHub Secret에 등록한 값들은 환경 변수로 사용할 수 있다.  
- `HOST=${{ secrets.EC2_HOST }}`
- `USER=${{ secrets.EC2_USER }}`

#### SSH 배포 시 주의 사항 
- `ssh -o StrictHostKeyChecking=no` 옵션을 써서 호스트키 체크를 비활성화 
    - 인터렉션이 없는 workflow를 위해 필요하다. (최초 한 번만 입력하면 됨)
- 대안 : EC2 인스턴스에서 `~/.ssh/authorized_keys` 파일에 접속자의 `public key` 추가 
  - `ssh-keygen -y -f {비밀키 경로} > public_key.pub` 명령어를 사용해 공개키를 만들 수 있다.
  - `public_key.pub` 부분도 원하는 경로와 이름으로 수정이 가능하다. 

<br>

### docker compose
- 여러 도커 컨테이너를 조합해서 관리하는 도구이다. 
- 싱글 호스트에서 여러개의 컨테이너를 하나로 묶어 관리할 수 있다.
#### 두 개의 서비스 실행하기 : Nginx + Nodejs 
1. `Nginx`를 통해 `Nodejs express`로 리버스 프록싱할 수 있도록 설정한다.
```nginx
server {
    location / {
        proxy_pass http://my-node:3000;  # my-node 서비스로 프록시
        proxy_set_header Host $host;  # 원본 요청의 호스트 헤더 전달
        proxy_set_header X-Real-IP $remote_addr;  # 클라이언트의 실제 IP 전달
    }
}
```
```dockerfile
FROM nginx:latest

# 기본 설정 파일 삭제
RUN rm /etc/nginx/conf.d/default.conf

# 커스텀 설정 파일 복사
COPY default.conf /etc/nginx/conf.d/
```
2. 루트 디렉토리에 `docker-compose.yml` 파일을 만든다. 
```yaml
services:
  wserver:
    build: ./nginx
    ports:
      - "80:80"
    depends_on:
      - my-node
# Node.js 백엔드 서버
  my-node:
    image: ghcr.io/ej31/jeff-ex:1.3
    command: ["npm","start"]
    expose:
      - "3000"
```

#### 사용 흐름 
1. `docker-compose.yml` 파일을 작성한다.
2. 명령어를 실행한다.
- 서비스 빌드 : `docker compose build` 
- 서비스 실행 : `docker compose up` 
- 서비스 실행, 빌드 같이 하기 : `docker compose up --build` 
- 백그라운드 실행 : `docker compose up -d` 
- 서비스 중지 : `docker compose down`
3. 모든 도커 컨테이너가 설정에 따라 자동으로 실행 및 관리된다. 

<br>


### docker-compose.yml 파일
- version : `docker compose`의 파일 버전을 지정하는 옵션으로 최근에는 불필요하지만 레거시에서는 사용된다. 


<br>


### Nginx 설정 파일
- `rewrite ^/app1/(.*)$ /$1 break` : 클라이언트의 요청 경로에서 `/app1/` 부분을 제거해서 실제 애플리케이션이 경로를 올바르게 인식하도록 한다. 
- `proxy_set_header` : 원본 요청의 헤더 정보를 전달해서 애플리케이션이 클라이언트의 정보를 인식할 수 있도록 한다. 
- 리버스 프록싱 시 `X-Real-IP`를 반드시 전달해줘야 백엔드에서 후처리가 가능하다. 
```plain text 
server {
    listen 80;  
    location /app1/ {
        rewrite ^/app1/(.*)$ /$1 break;  
        proxy_pass http://app1:3000;  
        proxy_set_header Host $host; 
        proxy_set_header X-Real-IP $remote_addr;  
    }
}
```
<br>


### docker 명령어 
- `docker compose down -v` : 실행 중인 컨테이너를 종료 및 삭제하는 명령 
  - `-v` 옵션을 통해 사용된 모든 볼륨을 삭제한다. 데이터베이스를 초기화 할 때 사용한다.  
- `docker compose ps` : 실행 중인 컨테이너의 상태를 확인하고 포트 매핑 정보를 표시하는 명령 

<br>


### 연결 풀링 사용
- 단일 데이터베이스 연결은 다수의 요청을 처리하는 데 비효율적이다.
- `MYSQL` 연결 생성 시 연결 풀링을 통해 다중 요청 처리 성능을 향상 시킬 수 있다.
- `mysql.createPool`을 사용해 연결 풀을 생성하는 방식으로 사용한다.  


<br>


### k8s 기본 구조 
- `MSA`를 기반으로 설계되어 리소스가 죽어도 시스템 전체가 중단되지 않는다.  
- `Master Node`와 `Worker Node`로 구성되어 있다.  
- `kubectl` 명령을 통해 클러스터를 관리한다. 
- `pod` : 하나 이상의 컨테이너를 포함하며 같은 `pod` 내의 컨테이너들은 네트워크와 저장소를 공유한다. 
#### master node (control plane)
- 클러스터를 관리하고 제어하는 역할을 하며, 클러스터의 전반적인 상태와 동작을 조율한다. 
- 클러스터 제어 로직을 담당하고 사용자와 클러스터 간 인터페이스를 제공하며, 리소스를 관리하고 스케줄링을 수행한다. 
- 구성 요소 : API server, etcd, controller manager, scheduler 
    - API server : 클러스터의 진입점 역할을 한다. 
    - etcd : 클러스터의 상태 데이터를 저장하는 분산 `key-value` 저장소이다. 
    - controller manager : 클러스터 상태를 원하는 상태로 유지하기 위해 다양한 컨트롤러가 작동한다. 
    - Scheduler : 새로 생성된 `pod`에 적당한 노드를 할당하고 노드 리소스 상태를 기반으로 최적의 배치를 결정한다.  
#### worker node (data plane)
- 클러스터에서 실제 애플리케이션 워크로드를 실행하는 역할을 담당한다.
- 애플리케이션 컨테이너 실행과 컨테이너 간 네트워크 통신을 처리한다. 
- 구성 요소 : Kubelet, Container Runtime, Kube-proxy
  - Kubelet: API Server와 통신해서 워커 노드에서 실행해야 할 작업을 수행하고 실행 중인 컨테이너를 모니터링하여 상태를 보고한다. 
  - Container Runtime : 컨테이너를 실행하는 데 필요한 소프트웨어이다. 
  - Kube-proxy : `pod` 간 네트워크 통신 지원 및 Service의 로드 밸런싱과 클러스터 내부 트래픽 라우팅 처리를 담당한다. 


<br>

### 오늘의 회고
- github actions가 손에 익지 않아 실습하는데 시간이 많이 소요된다. 익숙해 질 때까지 연습을 많이 하는 것이 제일 좋은 방법일 것 같다.
- 복습할 내용이 많은데 단순히 내용 정리에서 끝내지 않고 실습을 반복하며 프로젝트에 적용해보는 것이 제대로 숙지하는 데 도움이 될 것 같다.  



<br>

[참고]
- github action : https://docs.github.com/en/actions